<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>c49ca2ad403e4131a5c3da3cca577cfd</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div id="ecde19f2" class="cell code" data-execution_count="6">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This is a sample Notebook to demonstrate how to read &quot;MNIST Dataset&quot;</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np <span class="co"># linear algebra</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> struct</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> array <span class="im">import</span> array</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> os.path <span class="im">import</span> join</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># MNIST Data Loader Class</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MnistDataloader(<span class="bu">object</span>):</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, training_images_filepath, training_labels_filepath,</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>                 test_images_filepath, test_labels_filepath):</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.training_images_filepath <span class="op">=</span> training_images_filepath</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.training_labels_filepath <span class="op">=</span> training_labels_filepath</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.test_images_filepath <span class="op">=</span> test_images_filepath</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.test_labels_filepath <span class="op">=</span> test_labels_filepath</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> read_images_labels(<span class="va">self</span>, images_filepath, labels_filepath):        </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> []</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(labels_filepath, <span class="st">&#39;rb&#39;</span>) <span class="im">as</span> <span class="bu">file</span>:</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>            magic, size <span class="op">=</span> struct.unpack(<span class="st">&quot;&gt;II&quot;</span>, <span class="bu">file</span>.read(<span class="dv">8</span>))</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> magic <span class="op">!=</span> <span class="dv">2049</span>:</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>                <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">&#39;Magic number mismatch, expected 2049, got </span><span class="sc">{}</span><span class="st">&#39;</span>.<span class="bu">format</span>(magic))</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> array(<span class="st">&quot;B&quot;</span>, <span class="bu">file</span>.read())        </span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(images_filepath, <span class="st">&#39;rb&#39;</span>) <span class="im">as</span> <span class="bu">file</span>:</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>            magic, size, rows, cols <span class="op">=</span> struct.unpack(<span class="st">&quot;&gt;IIII&quot;</span>, <span class="bu">file</span>.read(<span class="dv">16</span>))</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> magic <span class="op">!=</span> <span class="dv">2051</span>:</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>                <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">&#39;Magic number mismatch, expected 2051, got </span><span class="sc">{}</span><span class="st">&#39;</span>.<span class="bu">format</span>(magic))</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>            image_data <span class="op">=</span> array(<span class="st">&quot;B&quot;</span>, <span class="bu">file</span>.read())        </span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        images <span class="op">=</span> []</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(size):</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>            images.append([<span class="dv">0</span>] <span class="op">*</span> rows <span class="op">*</span> cols)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(size):</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> np.array(image_data[i <span class="op">*</span> rows <span class="op">*</span> cols:(i <span class="op">+</span> <span class="dv">1</span>) <span class="op">*</span> rows <span class="op">*</span> cols])</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> img.reshape(<span class="dv">28</span>, <span class="dv">28</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>            images[i][:] <span class="op">=</span> img            </span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> images, labels</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> load_data(<span class="va">self</span>):</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>        x_train, y_train <span class="op">=</span> <span class="va">self</span>.read_images_labels(<span class="va">self</span>.training_images_filepath, <span class="va">self</span>.training_labels_filepath)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>        x_test, y_test <span class="op">=</span> <span class="va">self</span>.read_images_labels(<span class="va">self</span>.test_images_filepath, <span class="va">self</span>.test_labels_filepath)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (x_train, y_train), (x_test, y_test)</span></code></pre></div>
</div>
<div id="33f62608" class="cell code" data-execution_count="7">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Set file paths for MNIST dataset files</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>mnist_path <span class="op">=</span> <span class="st">&#39;mnist&#39;</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>training_images_filepath <span class="op">=</span> join(mnist_path, <span class="st">&#39;train-images-idx3-ubyte/train-images-idx3-ubyte&#39;</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>training_labels_filepath <span class="op">=</span> join(mnist_path, <span class="st">&#39;train-labels-idx1-ubyte/train-labels-idx1-ubyte&#39;</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>test_images_filepath <span class="op">=</span> join(mnist_path, <span class="st">&#39;t10k-images-idx3-ubyte/t10k-images-idx3-ubyte&#39;</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>test_labels_filepath <span class="op">=</span> join(mnist_path, <span class="st">&#39;t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte&#39;</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Load MNIST dataset</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Loading MNIST dataset...&quot;</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>mnist_dataloader <span class="op">=</span> MnistDataloader(training_images_filepath, training_labels_filepath, </span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>                                   test_images_filepath, test_labels_filepath)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span> mnist_dataloader.load_data()</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Training data: </span><span class="sc">{</span><span class="bu">len</span>(x_train)<span class="sc">}</span><span class="ss"> images&quot;</span>)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Training labels: </span><span class="sc">{</span><span class="bu">len</span>(y_train)<span class="sc">}</span><span class="ss"> labels&quot;</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Test data: </span><span class="sc">{</span><span class="bu">len</span>(x_test)<span class="sc">}</span><span class="ss"> images&quot;</span>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Test labels: </span><span class="sc">{</span><span class="bu">len</span>(y_test)<span class="sc">}</span><span class="ss"> labels&quot;</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Image shape: </span><span class="sc">{</span>np<span class="sc">.</span>array(x_train[<span class="dv">0</span>])<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Dataset loaded successfully!&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Loading MNIST dataset...
Training data: 60000 images
Training labels: 60000 labels
Test data: 10000 images
Test labels: 10000 labels
Image shape: (28, 28)
Dataset loaded successfully!
</code></pre>
</div>
</div>
<div id="b060a519" class="cell code" data-execution_count="8">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Display 5 sample inputs and outputs</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">3</span>))</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display the image</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">5</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    plt.imshow(np.array(x_train[i]), cmap<span class="op">=</span><span class="st">&#39;gray&#39;</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f&#39;Input: Digit </span><span class="sc">{</span>y_train[i]<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;5 Sample MNIST Training Images with Labels&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Print additional information about the samples</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Sample Details:&quot;</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Sample </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: Label = </span><span class="sc">{</span>y_train[i]<span class="sc">}</span><span class="ss">, Image shape = </span><span class="sc">{</span>np<span class="sc">.</span>array(x_train[i])<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;  Pixel value range: </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">min</span>(x_train[i])<span class="sc">}</span><span class="ss"> to </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">max</span>(x_train[i])<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;  Mean pixel value: </span><span class="sc">{</span>np<span class="sc">.</span>mean(x_train[i])<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_637a505316254e4c82a7b332a1076792/9422de49045444a7716196b26642c59c03b38651.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Sample Details:
Sample 1: Label = 5, Image shape = (28, 28)
  Pixel value range: 0 to 255
  Mean pixel value: 35.11

Sample 2: Label = 0, Image shape = (28, 28)
  Pixel value range: 0 to 255
  Mean pixel value: 39.66

Sample 3: Label = 4, Image shape = (28, 28)
  Pixel value range: 0 to 255
  Mean pixel value: 24.80

Sample 4: Label = 1, Image shape = (28, 28)
  Pixel value range: 0 to 255
  Mean pixel value: 21.86

Sample 5: Label = 9, Image shape = (28, 28)
  Pixel value range: 0 to 255
  Mean pixel value: 29.61

</code></pre>
</div>
</div>
<div id="6682822c" class="cell code" data-execution_count="9">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Data Preprocessing for Neural Network</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Preprocessing data...&quot;</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to numpy arrays and normalize pixel values to [0, 1]</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> np.array([np.array(img).flatten() <span class="cf">for</span> img <span class="kw">in</span> x_train]) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> np.array([np.array(img).flatten() <span class="cf">for</span> img <span class="kw">in</span> x_test]) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># One-hot encode labels</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> to_one_hot(labels, num_classes<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    one_hot <span class="op">=</span> np.zeros((<span class="bu">len</span>(labels), num_classes))</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, label <span class="kw">in</span> <span class="bu">enumerate</span>(labels):</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        one_hot[i, label] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> one_hot</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>Y_train <span class="op">=</span> to_one_hot(y_train)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>Y_test <span class="op">=</span> to_one_hot(y_test)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Split training data into train and validation sets (80-20 split)</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>val_split <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.8</span> <span class="op">*</span> <span class="bu">len</span>(X_train))</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>X_val <span class="op">=</span> X_train[val_split:]</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>Y_val <span class="op">=</span> Y_train[val_split:]</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train[:val_split]</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>Y_train <span class="op">=</span> Y_train[:val_split]</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Training set: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> samples, </span><span class="sc">{</span>X_train<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> features&quot;</span>)</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Validation set: </span><span class="sc">{</span>X_val<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> samples&quot;</span>)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Test set: </span><span class="sc">{</span>X_test<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> samples&quot;</span>)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Input shape: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> (784 = 28x28)&quot;</span>)</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Output shape: </span><span class="sc">{</span>Y_train<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> (10 classes)&quot;</span>)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Pixel value range: [</span><span class="sc">{</span>X_train<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.1f}</span><span class="ss">, </span><span class="sc">{</span>X_train<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.1f}</span><span class="ss">]&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Preprocessing data...
Training set: 48000 samples, 784 features
Validation set: 12000 samples
Test set: 10000 samples
Input shape: 784 (784 = 28x28)
Output shape: 10 (10 classes)
Pixel value range: [0.0, 1.0]
</code></pre>
</div>
</div>
<div id="ecce597a" class="cell code" data-execution_count="10">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Activation Functions and Their Derivatives</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ActivationFunctions:</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> relu(x):</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;ReLU activation function&quot;&quot;&quot;</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.maximum(<span class="dv">0</span>, x)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> relu_derivative(x):</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Derivative of ReLU&quot;&quot;&quot;</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (x <span class="op">&gt;</span> <span class="dv">0</span>).astype(<span class="bu">float</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> softmax(x):</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Softmax activation function with numerical stability&quot;&quot;&quot;</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Subtract max for numerical stability</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>        exp_x <span class="op">=</span> np.exp(x <span class="op">-</span> np.<span class="bu">max</span>(x, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> exp_x <span class="op">/</span> np.<span class="bu">sum</span>(exp_x, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> sigmoid(x):</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Sigmoid activation function&quot;&quot;&quot;</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Clip x to prevent overflow</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> np.clip(x, <span class="op">-</span><span class="dv">250</span>, <span class="dv">250</span>)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>x))</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> sigmoid_derivative(x):</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Derivative of sigmoid&quot;&quot;&quot;</span></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>        s <span class="op">=</span> ActivationFunctions.sigmoid(x)</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> s <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> s)</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Test activation functions</span></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Testing activation functions...&quot;</span>)</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>test_input <span class="op">=</span> np.array([[<span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>]])</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;ReLU:&quot;</span>, ActivationFunctions.relu(test_input))</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;ReLU derivative:&quot;</span>, ActivationFunctions.relu_derivative(test_input))</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Sigmoid:&quot;</span>, ActivationFunctions.sigmoid(test_input))</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Softmax:&quot;</span>, ActivationFunctions.softmax(test_input))</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Activation functions ready!&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Testing activation functions...
ReLU: [[0 0 0 1 2]]
ReLU derivative: [[0. 0. 0. 1. 1.]]
Sigmoid: [[0.11920292 0.26894142 0.5        0.73105858 0.88079708]]
Softmax: [[0.01165623 0.03168492 0.08612854 0.23412166 0.63640865]]
Activation functions ready!
</code></pre>
</div>
</div>
<div id="e8ee914b" class="cell code" data-execution_count="11">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Weight Initialization Methods</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> WeightInitializer:</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> xavier_uniform(input_size, output_size):</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Xavier/Glorot uniform initialization&quot;&quot;&quot;</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        limit <span class="op">=</span> np.sqrt(<span class="fl">6.0</span> <span class="op">/</span> (input_size <span class="op">+</span> output_size))</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.random.uniform(<span class="op">-</span>limit, limit, (input_size, output_size))</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> he_uniform(input_size, output_size):</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;He uniform initialization (good for ReLU)&quot;&quot;&quot;</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>        limit <span class="op">=</span> np.sqrt(<span class="fl">6.0</span> <span class="op">/</span> input_size)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.random.uniform(<span class="op">-</span>limit, limit, (input_size, output_size))</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> he_normal(input_size, output_size):</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;He normal initialization (good for ReLU)&quot;&quot;&quot;</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>        std <span class="op">=</span> np.sqrt(<span class="fl">2.0</span> <span class="op">/</span> input_size)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.random.normal(<span class="dv">0</span>, std, (input_size, output_size))</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> zeros(size):</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Initialize with zeros (typically for biases)&quot;&quot;&quot;</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.zeros(size)</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Test weight initialization</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Testing weight initialization...&quot;</span>)</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>test_weights <span class="op">=</span> WeightInitializer.he_normal(<span class="dv">784</span>, <span class="dv">128</span>)</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;He normal weights shape: </span><span class="sc">{</span>test_weights<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Weight statistics - Mean: </span><span class="sc">{</span>test_weights<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">, Std: </span><span class="sc">{</span>test_weights<span class="sc">.</span>std()<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Weight initialization ready!&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Testing weight initialization...
He normal weights shape: (784, 128)
Weight statistics - Mean: -0.0001, Std: 0.0505
Weight initialization ready!
</code></pre>
</div>
</div>
<div id="e7a26c05" class="cell code" data-execution_count="12">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Loss Functions</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LossFunctions:</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> cross_entropy_loss(y_true, y_pred):</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Cross-entropy loss with numerical stability&quot;&quot;&quot;</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Clip predictions to prevent log(0)</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> np.clip(y_pred, <span class="fl">1e-15</span>, <span class="dv">1</span> <span class="op">-</span> <span class="fl">1e-15</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate cross-entropy loss</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="op">-</span>np.mean(np.<span class="bu">sum</span>(y_true <span class="op">*</span> np.log(y_pred), axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> cross_entropy_derivative(y_true, y_pred):</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Derivative of cross-entropy loss with respect to predictions&quot;&quot;&quot;</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For softmax + cross-entropy, the derivative simplifies to:</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (y_pred <span class="op">-</span> y_true) <span class="op">/</span> y_true.shape[<span class="dv">0</span>]</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> calculate_accuracy(y_true, y_pred):</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Calculate accuracy from one-hot encoded labels&quot;&quot;&quot;</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>        y_true_labels <span class="op">=</span> np.argmax(y_true, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>        y_pred_labels <span class="op">=</span> np.argmax(y_pred, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.mean(y_true_labels <span class="op">==</span> y_pred_labels)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Test loss functions</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Testing loss functions...&quot;</span>)</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Create dummy predictions</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>y_true_test <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>], [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>], [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>]])</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>y_pred_test <span class="op">=</span> np.array([[<span class="fl">0.9</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span>], [<span class="fl">0.1</span>, <span class="fl">0.8</span>, <span class="fl">0.1</span>], [<span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.6</span>]])</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> LossFunctions.cross_entropy_loss(y_true_test, y_pred_test)</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> LossFunctions.calculate_accuracy(y_true_test, y_pred_test)</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Test loss: </span><span class="sc">{</span>loss<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Test accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Loss functions ready!&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Testing loss functions...
Test loss: 0.2798
Test accuracy: 1.0000
Loss functions ready!
</code></pre>
</div>
</div>
<div id="2ab240d3" class="cell code" data-execution_count="13">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Neural Network Class - Core Structure</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NeuralNetwork:</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, layer_sizes, learning_rate<span class="op">=</span><span class="fl">0.001</span>, l2_lambda<span class="op">=</span><span class="fl">0.01</span>):</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">        Initialize neural network</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co">        layer_sizes: list of layer sizes [input_size, hidden1_size, hidden2_size, output_size]</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer_sizes <span class="op">=</span> layer_sizes</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learning_rate <span class="op">=</span> learning_rate</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.l2_lambda <span class="op">=</span> l2_lambda</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_layers <span class="op">=</span> <span class="bu">len</span>(layer_sizes)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize weights and biases</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights <span class="op">=</span> {}</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.biases <span class="op">=</span> {}</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize using He initialization for ReLU layers</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="va">self</span>.num_layers):</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">==</span> <span class="va">self</span>.num_layers <span class="op">-</span> <span class="dv">1</span>:  <span class="co"># Output layer - use Xavier</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.weights[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> WeightInitializer.xavier_uniform(</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>                    layer_sizes[i<span class="op">-</span><span class="dv">1</span>], layer_sizes[i]</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:  <span class="co"># Hidden layers - use He</span></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.weights[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> WeightInitializer.he_normal(</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>                    layer_sizes[i<span class="op">-</span><span class="dv">1</span>], layer_sizes[i]</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.biases[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> WeightInitializer.zeros(layer_sizes[i])</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Storage for forward pass values (needed for backprop)</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cache <span class="op">=</span> {}</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Neural Network initialized:&quot;</span>)</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Architecture: </span><span class="sc">{</span><span class="st">&#39; -&gt; &#39;</span><span class="sc">.</span>join(<span class="bu">map</span>(<span class="bu">str</span>, layer_sizes))<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Total parameters: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>_count_parameters()<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _count_parameters(<span class="va">self</span>):</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Count total number of parameters&quot;&quot;&quot;</span></span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>        total <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="va">self</span>.num_layers):</span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>            total <span class="op">+=</span> <span class="va">self</span>.weights[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>].size <span class="op">+</span> <span class="va">self</span>.biases[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>].size</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> total</span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, X):</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Forward propagation&quot;&quot;&quot;</span></span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cache[<span class="st">&#39;A0&#39;</span>] <span class="op">=</span> X  <span class="co"># Input layer</span></span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Hidden layers with ReLU</span></span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="va">self</span>.num_layers <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a>            Z <span class="op">=</span> np.dot(<span class="va">self</span>.cache[<span class="ss">f&#39;A</span><span class="sc">{</span>i<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="ss">&#39;</span>], <span class="va">self</span>.weights[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>]) <span class="op">+</span> <span class="va">self</span>.biases[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>]</span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a>            A <span class="op">=</span> ActivationFunctions.relu(Z)</span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.cache[<span class="ss">f&#39;Z</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> Z</span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.cache[<span class="ss">f&#39;A</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> A</span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Output layer with Softmax</span></span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>        i <span class="op">=</span> <span class="va">self</span>.num_layers <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a>        Z <span class="op">=</span> np.dot(<span class="va">self</span>.cache[<span class="ss">f&#39;A</span><span class="sc">{</span>i<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="ss">&#39;</span>], <span class="va">self</span>.weights[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>]) <span class="op">+</span> <span class="va">self</span>.biases[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>]</span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a>        A <span class="op">=</span> ActivationFunctions.softmax(Z)</span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cache[<span class="ss">f&#39;Z</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> Z</span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cache[<span class="ss">f&#39;A</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> A</span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-63"><a href="#cb14-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> A</span>
<span id="cb14-64"><a href="#cb14-64" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-65"><a href="#cb14-65" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb14-66"><a href="#cb14-66" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Make predictions&quot;&quot;&quot;</span></span>
<span id="cb14-67"><a href="#cb14-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.forward(X)</span>
<span id="cb14-68"><a href="#cb14-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-69"><a href="#cb14-69" aria-hidden="true" tabindex="-1"></a><span class="co"># Test neural network initialization</span></span>
<span id="cb14-70"><a href="#cb14-70" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Testing Neural Network initialization...&quot;</span>)</span>
<span id="cb14-71"><a href="#cb14-71" aria-hidden="true" tabindex="-1"></a>nn <span class="op">=</span> NeuralNetwork([<span class="dv">784</span>, <span class="dv">128</span>, <span class="dv">64</span>, <span class="dv">10</span>], learning_rate<span class="op">=</span><span class="fl">0.001</span>, l2_lambda<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb14-72"><a href="#cb14-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-73"><a href="#cb14-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Test forward pass with small batch</span></span>
<span id="cb14-74"><a href="#cb14-74" aria-hidden="true" tabindex="-1"></a>test_batch <span class="op">=</span> X_train[:<span class="dv">5</span>]</span>
<span id="cb14-75"><a href="#cb14-75" aria-hidden="true" tabindex="-1"></a>test_output <span class="op">=</span> nn.forward(test_batch)</span>
<span id="cb14-76"><a href="#cb14-76" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Test forward pass - Input shape: </span><span class="sc">{</span>test_batch<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb14-77"><a href="#cb14-77" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Output shape: </span><span class="sc">{</span>test_output<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb14-78"><a href="#cb14-78" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Output probabilities sum: </span><span class="sc">{</span>test_output<span class="sc">.</span><span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)<span class="sc">}</span><span class="ss">&quot;</span>)  <span class="co"># Should be close to 1</span></span>
<span id="cb14-79"><a href="#cb14-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Neural Network core ready!&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Testing Neural Network initialization...
Neural Network initialized:
Architecture: 784 -&gt; 128 -&gt; 64 -&gt; 10
Total parameters: 109386
Test forward pass - Input shape: (5, 784)
Output shape: (5, 10)
Output probabilities sum: [1. 1. 1. 1. 1.]
Neural Network core ready!
</code></pre>
</div>
</div>
<div id="3e14ab85" class="cell code" data-execution_count="14">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Backpropagation Implementation</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> backward(<span class="va">self</span>, X, Y):</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Backward propagation with L2 regularization&quot;&quot;&quot;</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> X.shape[<span class="dv">0</span>]  <span class="co"># batch size</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    gradients <span class="op">=</span> {}</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Output layer gradient (softmax + cross-entropy)</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> <span class="va">self</span>.num_layers <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    dZ <span class="op">=</span> LossFunctions.cross_entropy_derivative(Y, <span class="va">self</span>.cache[<span class="ss">f&#39;A</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>])</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    gradients[<span class="ss">f&#39;dW</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> np.dot(<span class="va">self</span>.cache[<span class="ss">f&#39;A</span><span class="sc">{</span>i<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="ss">&#39;</span>].T, dZ) <span class="op">+</span> <span class="va">self</span>.l2_lambda <span class="op">*</span> <span class="va">self</span>.weights[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>]</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    gradients[<span class="ss">f&#39;db</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> np.<span class="bu">sum</span>(dZ, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    dA_prev <span class="op">=</span> np.dot(dZ, <span class="va">self</span>.weights[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>].T)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Hidden layers gradients (ReLU)</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.num_layers <span class="op">-</span> <span class="dv">2</span>, <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>        dZ <span class="op">=</span> dA_prev <span class="op">*</span> ActivationFunctions.relu_derivative(<span class="va">self</span>.cache[<span class="ss">f&#39;Z</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>])</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>        gradients[<span class="ss">f&#39;dW</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> np.dot(<span class="va">self</span>.cache[<span class="ss">f&#39;A</span><span class="sc">{</span>i<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="ss">&#39;</span>].T, dZ) <span class="op">+</span> <span class="va">self</span>.l2_lambda <span class="op">*</span> <span class="va">self</span>.weights[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>]</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>        gradients[<span class="ss">f&#39;db</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> np.<span class="bu">sum</span>(dZ, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">&gt;</span> <span class="dv">1</span>:  <span class="co"># Don&#39;t compute dA_prev for input layer</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>            dA_prev <span class="op">=</span> np.dot(dZ, <span class="va">self</span>.weights[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>].T)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> gradients</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_parameters(<span class="va">self</span>, gradients):</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Update parameters using gradients&quot;&quot;&quot;</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="va">self</span>.num_layers):</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">-=</span> <span class="va">self</span>.learning_rate <span class="op">*</span> gradients[<span class="ss">f&#39;dW</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>]</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.biases[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">-=</span> <span class="va">self</span>.learning_rate <span class="op">*</span> gradients[<span class="ss">f&#39;db</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>]</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_loss(<span class="va">self</span>, Y_true, Y_pred):</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Compute total loss including L2 regularization&quot;&quot;&quot;</span></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Cross-entropy loss</span></span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>    ce_loss <span class="op">=</span> LossFunctions.cross_entropy_loss(Y_true, Y_pred)</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># L2 regularization loss</span></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>    l2_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="va">self</span>.num_layers):</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>        l2_loss <span class="op">+=</span> np.<span class="bu">sum</span>(<span class="va">self</span>.weights[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>    l2_loss <span class="op">*=</span> <span class="va">self</span>.l2_lambda <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ce_loss <span class="op">+</span> l2_loss</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Add methods to NeuralNetwork class</span></span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>NeuralNetwork.backward <span class="op">=</span> backward</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>NeuralNetwork.update_parameters <span class="op">=</span> update_parameters</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>NeuralNetwork.compute_loss <span class="op">=</span> compute_loss</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Backpropagation methods added to Neural Network class!&quot;</span>)</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Methods: backward, update_parameters, compute_loss&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Backpropagation methods added to Neural Network class!
Methods: backward, update_parameters, compute_loss
</code></pre>
</div>
</div>
<div id="98465974" class="cell code" data-execution_count="15">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Adam Optimizer Implementation</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AdamOptimizer:</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, neural_network, learning_rate<span class="op">=</span><span class="fl">0.001</span>, beta1<span class="op">=</span><span class="fl">0.9</span>, beta2<span class="op">=</span><span class="fl">0.999</span>, epsilon<span class="op">=</span><span class="fl">1e-8</span>):</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.nn <span class="op">=</span> neural_network</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learning_rate <span class="op">=</span> learning_rate</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.beta1 <span class="op">=</span> beta1</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.beta2 <span class="op">=</span> beta2</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.epsilon <span class="op">=</span> epsilon</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.t <span class="op">=</span> <span class="dv">0</span>  <span class="co"># time step</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize moment estimates</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.m <span class="op">=</span> {}  <span class="co"># first moment</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.v <span class="op">=</span> {}  <span class="co"># second moment</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="va">self</span>.nn.num_layers):</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.m[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> np.zeros_like(<span class="va">self</span>.nn.weights[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>])</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.m[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> np.zeros_like(<span class="va">self</span>.nn.biases[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>])</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.v[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> np.zeros_like(<span class="va">self</span>.nn.weights[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>])</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.v[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> np.zeros_like(<span class="va">self</span>.nn.biases[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>])</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update(<span class="va">self</span>, gradients):</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Update parameters using Adam optimization&quot;&quot;&quot;</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.t <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="va">self</span>.nn.num_layers):</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update biased first moment estimate</span></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.m[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> <span class="va">self</span>.beta1 <span class="op">*</span> <span class="va">self</span>.m[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.beta1) <span class="op">*</span> gradients[<span class="ss">f&#39;dW</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>]</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.m[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> <span class="va">self</span>.beta1 <span class="op">*</span> <span class="va">self</span>.m[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.beta1) <span class="op">*</span> gradients[<span class="ss">f&#39;db</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>]</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update biased second raw moment estimate</span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.v[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> <span class="va">self</span>.beta2 <span class="op">*</span> <span class="va">self</span>.v[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.beta2) <span class="op">*</span> (gradients[<span class="ss">f&#39;dW</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.v[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> <span class="va">self</span>.beta2 <span class="op">*</span> <span class="va">self</span>.v[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.beta2) <span class="op">*</span> (gradients[<span class="ss">f&#39;db</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute bias-corrected first moment estimate</span></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>            m_corrected_W <span class="op">=</span> <span class="va">self</span>.m[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.beta1 <span class="op">**</span> <span class="va">self</span>.t)</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>            m_corrected_b <span class="op">=</span> <span class="va">self</span>.m[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.beta1 <span class="op">**</span> <span class="va">self</span>.t)</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute bias-corrected second raw moment estimate</span></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>            v_corrected_W <span class="op">=</span> <span class="va">self</span>.v[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.beta2 <span class="op">**</span> <span class="va">self</span>.t)</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>            v_corrected_b <span class="op">=</span> <span class="va">self</span>.v[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.beta2 <span class="op">**</span> <span class="va">self</span>.t)</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update parameters</span></span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.nn.weights[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">-=</span> <span class="va">self</span>.learning_rate <span class="op">*</span> m_corrected_W <span class="op">/</span> (np.sqrt(v_corrected_W) <span class="op">+</span> <span class="va">self</span>.epsilon)</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.nn.biases[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">-=</span> <span class="va">self</span>.learning_rate <span class="op">*</span> m_corrected_b <span class="op">/</span> (np.sqrt(v_corrected_b) <span class="op">+</span> <span class="va">self</span>.epsilon)</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Learning rate scheduler</span></span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LearningRateScheduler:</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> exponential_decay(initial_lr, epoch, decay_rate<span class="op">=</span><span class="fl">0.95</span>, decay_steps<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Exponential decay learning rate&quot;&quot;&quot;</span></span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> initial_lr <span class="op">*</span> (decay_rate <span class="op">**</span> (epoch <span class="op">//</span> decay_steps))</span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> step_decay(initial_lr, epoch, drop_rate<span class="op">=</span><span class="fl">0.5</span>, epochs_drop<span class="op">=</span><span class="dv">20</span>):</span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Step decay learning rate&quot;&quot;&quot;</span></span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> initial_lr <span class="op">*</span> (drop_rate <span class="op">**</span> (epoch <span class="op">//</span> epochs_drop))</span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Adam Optimizer and Learning Rate Scheduler implemented!&quot;</span>)</span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Features: Adaptive learning rates, momentum, bias correction&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Adam Optimizer and Learning Rate Scheduler implemented!
Features: Adaptive learning rates, momentum, bias correction
</code></pre>
</div>
</div>
<div id="f93e85a8" class="cell code" data-execution_count="16">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Training Loop with Monitoring</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_network(neural_network, X_train, Y_train, X_val, Y_val, </span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>                 epochs<span class="op">=</span><span class="dv">50</span>, batch_size<span class="op">=</span><span class="dv">128</span>, use_adam<span class="op">=</span><span class="va">True</span>, verbose<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Train the neural network with monitoring and early stopping</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize optimizer</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> use_adam:</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>        optimizer <span class="op">=</span> AdamOptimizer(neural_network, learning_rate<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training history</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> {</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;train_loss&#39;</span>: [], <span class="st">&#39;train_acc&#39;</span>: [],</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;val_loss&#39;</span>: [], <span class="st">&#39;val_acc&#39;</span>: [],</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;epoch_time&#39;</span>: []</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Early stopping parameters</span></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>    best_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">&#39;inf&#39;</span>)</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>    patience <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>    patience_counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate number of batches</span></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>    num_batches <span class="op">=</span> <span class="bu">len</span>(X_train) <span class="op">//</span> batch_size</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Starting training...&quot;</span>)</span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Architecture: </span><span class="sc">{</span>neural_network<span class="sc">.</span>layer_sizes<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Optimizer: </span><span class="sc">{</span><span class="st">&#39;Adam&#39;</span> <span class="cf">if</span> use_adam <span class="cf">else</span> <span class="st">&#39;SGD&#39;</span><span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Batch size: </span><span class="sc">{</span>batch_size<span class="sc">}</span><span class="ss">, Batches per epoch: </span><span class="sc">{</span>num_batches<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;-&quot;</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>        start_time <span class="op">=</span> time.time()</span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Shuffle training data</span></span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a>        indices <span class="op">=</span> np.random.permutation(<span class="bu">len</span>(X_train))</span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>        X_train_shuffled <span class="op">=</span> X_train[indices]</span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a>        Y_train_shuffled <span class="op">=</span> Y_train[indices]</span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Training phase</span></span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a>        train_losses <span class="op">=</span> []</span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a>        train_predictions <span class="op">=</span> []</span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> <span class="bu">range</span>(num_batches):</span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get batch</span></span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a>            start_idx <span class="op">=</span> batch <span class="op">*</span> batch_size</span>
<span id="cb20-52"><a href="#cb20-52" aria-hidden="true" tabindex="-1"></a>            end_idx <span class="op">=</span> <span class="bu">min</span>((batch <span class="op">+</span> <span class="dv">1</span>) <span class="op">*</span> batch_size, <span class="bu">len</span>(X_train))</span>
<span id="cb20-53"><a href="#cb20-53" aria-hidden="true" tabindex="-1"></a>            X_batch <span class="op">=</span> X_train_shuffled[start_idx:end_idx]</span>
<span id="cb20-54"><a href="#cb20-54" aria-hidden="true" tabindex="-1"></a>            Y_batch <span class="op">=</span> Y_train_shuffled[start_idx:end_idx]</span>
<span id="cb20-55"><a href="#cb20-55" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb20-56"><a href="#cb20-56" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Forward pass</span></span>
<span id="cb20-57"><a href="#cb20-57" aria-hidden="true" tabindex="-1"></a>            predictions <span class="op">=</span> neural_network.forward(X_batch)</span>
<span id="cb20-58"><a href="#cb20-58" aria-hidden="true" tabindex="-1"></a>            train_predictions.append(predictions)</span>
<span id="cb20-59"><a href="#cb20-59" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb20-60"><a href="#cb20-60" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute loss</span></span>
<span id="cb20-61"><a href="#cb20-61" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> neural_network.compute_loss(Y_batch, predictions)</span>
<span id="cb20-62"><a href="#cb20-62" aria-hidden="true" tabindex="-1"></a>            train_losses.append(loss)</span>
<span id="cb20-63"><a href="#cb20-63" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb20-64"><a href="#cb20-64" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Backward pass</span></span>
<span id="cb20-65"><a href="#cb20-65" aria-hidden="true" tabindex="-1"></a>            gradients <span class="op">=</span> neural_network.backward(X_batch, Y_batch)</span>
<span id="cb20-66"><a href="#cb20-66" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb20-67"><a href="#cb20-67" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update parameters</span></span>
<span id="cb20-68"><a href="#cb20-68" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> use_adam:</span>
<span id="cb20-69"><a href="#cb20-69" aria-hidden="true" tabindex="-1"></a>                optimizer.update(gradients)</span>
<span id="cb20-70"><a href="#cb20-70" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb20-71"><a href="#cb20-71" aria-hidden="true" tabindex="-1"></a>                neural_network.update_parameters(gradients)</span>
<span id="cb20-72"><a href="#cb20-72" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb20-73"><a href="#cb20-73" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate training metrics</span></span>
<span id="cb20-74"><a href="#cb20-74" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">=</span> np.mean(train_losses)</span>
<span id="cb20-75"><a href="#cb20-75" aria-hidden="true" tabindex="-1"></a>        train_predictions <span class="op">=</span> np.vstack(train_predictions)</span>
<span id="cb20-76"><a href="#cb20-76" aria-hidden="true" tabindex="-1"></a>        train_acc <span class="op">=</span> LossFunctions.calculate_accuracy(</span>
<span id="cb20-77"><a href="#cb20-77" aria-hidden="true" tabindex="-1"></a>            Y_train_shuffled[:<span class="bu">len</span>(train_predictions)], train_predictions</span>
<span id="cb20-78"><a href="#cb20-78" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb20-79"><a href="#cb20-79" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb20-80"><a href="#cb20-80" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Validation phase</span></span>
<span id="cb20-81"><a href="#cb20-81" aria-hidden="true" tabindex="-1"></a>        val_predictions <span class="op">=</span> neural_network.forward(X_val)</span>
<span id="cb20-82"><a href="#cb20-82" aria-hidden="true" tabindex="-1"></a>        val_loss <span class="op">=</span> neural_network.compute_loss(Y_val, val_predictions)</span>
<span id="cb20-83"><a href="#cb20-83" aria-hidden="true" tabindex="-1"></a>        val_acc <span class="op">=</span> LossFunctions.calculate_accuracy(Y_val, val_predictions)</span>
<span id="cb20-84"><a href="#cb20-84" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb20-85"><a href="#cb20-85" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Record history</span></span>
<span id="cb20-86"><a href="#cb20-86" aria-hidden="true" tabindex="-1"></a>        epoch_time <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb20-87"><a href="#cb20-87" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">&#39;train_loss&#39;</span>].append(train_loss)</span>
<span id="cb20-88"><a href="#cb20-88" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">&#39;train_acc&#39;</span>].append(train_acc)</span>
<span id="cb20-89"><a href="#cb20-89" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">&#39;val_loss&#39;</span>].append(val_loss)</span>
<span id="cb20-90"><a href="#cb20-90" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">&#39;val_acc&#39;</span>].append(val_acc)</span>
<span id="cb20-91"><a href="#cb20-91" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">&#39;epoch_time&#39;</span>].append(epoch_time)</span>
<span id="cb20-92"><a href="#cb20-92" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb20-93"><a href="#cb20-93" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print progress</span></span>
<span id="cb20-94"><a href="#cb20-94" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose <span class="kw">and</span> (epoch <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">5</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb20-95"><a href="#cb20-95" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">:3d}</span><span class="ss">/</span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss"> | &quot;</span></span>
<span id="cb20-96"><a href="#cb20-96" aria-hidden="true" tabindex="-1"></a>                  <span class="ss">f&quot;Train Loss: </span><span class="sc">{</span>train_loss<span class="sc">:.4f}</span><span class="ss"> | Train Acc: </span><span class="sc">{</span>train_acc<span class="sc">:.4f}</span><span class="ss"> | &quot;</span></span>
<span id="cb20-97"><a href="#cb20-97" aria-hidden="true" tabindex="-1"></a>                  <span class="ss">f&quot;Val Loss: </span><span class="sc">{</span>val_loss<span class="sc">:.4f}</span><span class="ss"> | Val Acc: </span><span class="sc">{</span>val_acc<span class="sc">:.4f}</span><span class="ss"> | &quot;</span></span>
<span id="cb20-98"><a href="#cb20-98" aria-hidden="true" tabindex="-1"></a>                  <span class="ss">f&quot;Time: </span><span class="sc">{</span>epoch_time<span class="sc">:.2f}</span><span class="ss">s&quot;</span>)</span>
<span id="cb20-99"><a href="#cb20-99" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb20-100"><a href="#cb20-100" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Early stopping</span></span>
<span id="cb20-101"><a href="#cb20-101" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> val_loss <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb20-102"><a href="#cb20-102" aria-hidden="true" tabindex="-1"></a>            best_val_loss <span class="op">=</span> val_loss</span>
<span id="cb20-103"><a href="#cb20-103" aria-hidden="true" tabindex="-1"></a>            patience_counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb20-104"><a href="#cb20-104" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb20-105"><a href="#cb20-105" aria-hidden="true" tabindex="-1"></a>            patience_counter <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb20-106"><a href="#cb20-106" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> patience_counter <span class="op">&gt;=</span> patience:</span>
<span id="cb20-107"><a href="#cb20-107" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f&quot;Early stopping at epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb20-108"><a href="#cb20-108" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb20-109"><a href="#cb20-109" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb20-110"><a href="#cb20-110" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Learning rate scheduling (if using Adam)</span></span>
<span id="cb20-111"><a href="#cb20-111" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> use_adam <span class="kw">and</span> (epoch <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">20</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb20-112"><a href="#cb20-112" aria-hidden="true" tabindex="-1"></a>            optimizer.learning_rate <span class="op">*=</span> <span class="fl">0.8</span></span>
<span id="cb20-113"><a href="#cb20-113" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-114"><a href="#cb20-114" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;-&quot;</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb20-115"><a href="#cb20-115" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Training completed!&quot;</span>)</span>
<span id="cb20-116"><a href="#cb20-116" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Best validation loss: </span><span class="sc">{</span>best_val_loss<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb20-117"><a href="#cb20-117" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Final validation accuracy: </span><span class="sc">{</span>history[<span class="st">&#39;val_acc&#39;</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb20-118"><a href="#cb20-118" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-119"><a href="#cb20-119" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> history</span>
<span id="cb20-120"><a href="#cb20-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-121"><a href="#cb20-121" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Training function implemented!&quot;</span>)</span>
<span id="cb20-122"><a href="#cb20-122" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Features: Mini-batch training, Adam optimizer, early stopping, learning rate decay&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Training function implemented!
Features: Mini-batch training, Adam optimizer, early stopping, learning rate decay
</code></pre>
</div>
</div>
<div id="24a1dab3" class="cell code" data-execution_count="17">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluation and Visualization Functions</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_training_history(history):</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Plot training and validation metrics&quot;&quot;&quot;</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot loss</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].plot(history[<span class="st">&#39;train_loss&#39;</span>], label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>, color<span class="op">=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].plot(history[<span class="st">&#39;val_loss&#39;</span>], label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>, color<span class="op">=</span><span class="st">&#39;red&#39;</span>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_title(<span class="st">&#39;Training and Validation Loss&#39;</span>)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_xlabel(<span class="st">&#39;Epoch&#39;</span>)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_ylabel(<span class="st">&#39;Loss&#39;</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].legend()</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].grid(<span class="va">True</span>)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot accuracy</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].plot(history[<span class="st">&#39;train_acc&#39;</span>], label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>, color<span class="op">=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].plot(history[<span class="st">&#39;val_acc&#39;</span>], label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>, color<span class="op">=</span><span class="st">&#39;red&#39;</span>)</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_title(<span class="st">&#39;Training and Validation Accuracy&#39;</span>)</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_xlabel(<span class="st">&#39;Epoch&#39;</span>)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_ylabel(<span class="st">&#39;Accuracy&#39;</span>)</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].legend()</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].grid(<span class="va">True</span>)</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_confusion_matrix(y_true, y_pred, class_names<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Create and plot confusion matrix&quot;&quot;&quot;</span></span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> class_names <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>        class_names <span class="op">=</span> [<span class="bu">str</span>(i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>)]</span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert one-hot to labels</span></span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>    y_true_labels <span class="op">=</span> np.argmax(y_true, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a>    y_pred_labels <span class="op">=</span> np.argmax(y_pred, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create confusion matrix</span></span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a>    cm <span class="op">=</span> np.zeros((<span class="dv">10</span>, <span class="dv">10</span>), dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> true_label, pred_label <span class="kw">in</span> <span class="bu">zip</span>(y_true_labels, y_pred_labels):</span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a>        cm[true_label, pred_label] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot confusion matrix</span></span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a>    plt.imshow(cm, interpolation<span class="op">=</span><span class="st">&#39;nearest&#39;</span>, cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">&#39;Confusion Matrix&#39;</span>)</span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a>    plt.colorbar()</span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add labels</span></span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a>    tick_marks <span class="op">=</span> np.arange(<span class="dv">10</span>)</span>
<span id="cb22-51"><a href="#cb22-51" aria-hidden="true" tabindex="-1"></a>    plt.xticks(tick_marks, class_names)</span>
<span id="cb22-52"><a href="#cb22-52" aria-hidden="true" tabindex="-1"></a>    plt.yticks(tick_marks, class_names)</span>
<span id="cb22-53"><a href="#cb22-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-54"><a href="#cb22-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add text annotations</span></span>
<span id="cb22-55"><a href="#cb22-55" aria-hidden="true" tabindex="-1"></a>    thresh <span class="op">=</span> cm.<span class="bu">max</span>() <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb22-56"><a href="#cb22-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb22-57"><a href="#cb22-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb22-58"><a href="#cb22-58" aria-hidden="true" tabindex="-1"></a>            plt.text(j, i, <span class="bu">format</span>(cm[i, j], <span class="st">&#39;d&#39;</span>),</span>
<span id="cb22-59"><a href="#cb22-59" aria-hidden="true" tabindex="-1"></a>                    horizontalalignment<span class="op">=</span><span class="st">&quot;center&quot;</span>,</span>
<span id="cb22-60"><a href="#cb22-60" aria-hidden="true" tabindex="-1"></a>                    color<span class="op">=</span><span class="st">&quot;white&quot;</span> <span class="cf">if</span> cm[i, j] <span class="op">&gt;</span> thresh <span class="cf">else</span> <span class="st">&quot;black&quot;</span>)</span>
<span id="cb22-61"><a href="#cb22-61" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-62"><a href="#cb22-62" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">&#39;True Label&#39;</span>)</span>
<span id="cb22-63"><a href="#cb22-63" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">&#39;Predicted Label&#39;</span>)</span>
<span id="cb22-64"><a href="#cb22-64" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb22-65"><a href="#cb22-65" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb22-66"><a href="#cb22-66" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-67"><a href="#cb22-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cm</span>
<span id="cb22-68"><a href="#cb22-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-69"><a href="#cb22-69" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_predictions(neural_network, X_test, Y_test, num_samples<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb22-70"><a href="#cb22-70" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Show sample predictions with images&quot;&quot;&quot;</span></span>
<span id="cb22-71"><a href="#cb22-71" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> neural_network.predict(X_test[:num_samples])</span>
<span id="cb22-72"><a href="#cb22-72" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-73"><a href="#cb22-73" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">3</span>))</span>
<span id="cb22-74"><a href="#cb22-74" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_samples):</span>
<span id="cb22-75"><a href="#cb22-75" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="dv">1</span>, num_samples, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb22-76"><a href="#cb22-76" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-77"><a href="#cb22-77" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Reshape and display image</span></span>
<span id="cb22-78"><a href="#cb22-78" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> X_test[i].reshape(<span class="dv">28</span>, <span class="dv">28</span>)</span>
<span id="cb22-79"><a href="#cb22-79" aria-hidden="true" tabindex="-1"></a>        plt.imshow(image, cmap<span class="op">=</span><span class="st">&#39;gray&#39;</span>)</span>
<span id="cb22-80"><a href="#cb22-80" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-81"><a href="#cb22-81" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get true and predicted labels</span></span>
<span id="cb22-82"><a href="#cb22-82" aria-hidden="true" tabindex="-1"></a>        true_label <span class="op">=</span> np.argmax(Y_test[i])</span>
<span id="cb22-83"><a href="#cb22-83" aria-hidden="true" tabindex="-1"></a>        pred_label <span class="op">=</span> np.argmax(predictions[i])</span>
<span id="cb22-84"><a href="#cb22-84" aria-hidden="true" tabindex="-1"></a>        confidence <span class="op">=</span> predictions[i][pred_label]</span>
<span id="cb22-85"><a href="#cb22-85" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-86"><a href="#cb22-86" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Color based on correctness</span></span>
<span id="cb22-87"><a href="#cb22-87" aria-hidden="true" tabindex="-1"></a>        color <span class="op">=</span> <span class="st">&#39;green&#39;</span> <span class="cf">if</span> true_label <span class="op">==</span> pred_label <span class="cf">else</span> <span class="st">&#39;red&#39;</span></span>
<span id="cb22-88"><a href="#cb22-88" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="ss">f&#39;True: </span><span class="sc">{</span>true_label<span class="sc">}</span><span class="ch">\n</span><span class="ss">Pred: </span><span class="sc">{</span>pred_label<span class="sc">}</span><span class="ch">\n</span><span class="ss">Conf: </span><span class="sc">{</span>confidence<span class="sc">:.2f}</span><span class="ss">&#39;</span>, </span>
<span id="cb22-89"><a href="#cb22-89" aria-hidden="true" tabindex="-1"></a>                 color<span class="op">=</span>color, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb22-90"><a href="#cb22-90" aria-hidden="true" tabindex="-1"></a>        plt.axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb22-91"><a href="#cb22-91" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-92"><a href="#cb22-92" aria-hidden="true" tabindex="-1"></a>    plt.suptitle(<span class="st">&#39;Sample Predictions (Green=Correct, Red=Incorrect)&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb22-93"><a href="#cb22-93" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb22-94"><a href="#cb22-94" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb22-95"><a href="#cb22-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-96"><a href="#cb22-96" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_model(neural_network, X_test, Y_test, show_details<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb22-97"><a href="#cb22-97" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Comprehensive model evaluation&quot;&quot;&quot;</span></span>
<span id="cb22-98"><a href="#cb22-98" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Evaluating model on test set...&quot;</span>)</span>
<span id="cb22-99"><a href="#cb22-99" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-100"><a href="#cb22-100" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Make predictions</span></span>
<span id="cb22-101"><a href="#cb22-101" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> neural_network.predict(X_test)</span>
<span id="cb22-102"><a href="#cb22-102" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-103"><a href="#cb22-103" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate metrics</span></span>
<span id="cb22-104"><a href="#cb22-104" aria-hidden="true" tabindex="-1"></a>    test_loss <span class="op">=</span> neural_network.compute_loss(Y_test, predictions)</span>
<span id="cb22-105"><a href="#cb22-105" aria-hidden="true" tabindex="-1"></a>    test_accuracy <span class="op">=</span> LossFunctions.calculate_accuracy(Y_test, predictions)</span>
<span id="cb22-106"><a href="#cb22-106" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-107"><a href="#cb22-107" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Per-class accuracy</span></span>
<span id="cb22-108"><a href="#cb22-108" aria-hidden="true" tabindex="-1"></a>    y_true_labels <span class="op">=</span> np.argmax(Y_test, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb22-109"><a href="#cb22-109" aria-hidden="true" tabindex="-1"></a>    y_pred_labels <span class="op">=</span> np.argmax(predictions, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb22-110"><a href="#cb22-110" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-111"><a href="#cb22-111" aria-hidden="true" tabindex="-1"></a>    class_accuracies <span class="op">=</span> []</span>
<span id="cb22-112"><a href="#cb22-112" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb22-113"><a href="#cb22-113" aria-hidden="true" tabindex="-1"></a>        class_mask <span class="op">=</span> (y_true_labels <span class="op">==</span> i)</span>
<span id="cb22-114"><a href="#cb22-114" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.<span class="bu">sum</span>(class_mask) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb22-115"><a href="#cb22-115" aria-hidden="true" tabindex="-1"></a>            class_acc <span class="op">=</span> np.mean(y_pred_labels[class_mask] <span class="op">==</span> i)</span>
<span id="cb22-116"><a href="#cb22-116" aria-hidden="true" tabindex="-1"></a>            class_accuracies.append(class_acc)</span>
<span id="cb22-117"><a href="#cb22-117" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb22-118"><a href="#cb22-118" aria-hidden="true" tabindex="-1"></a>            class_accuracies.append(<span class="fl">0.0</span>)</span>
<span id="cb22-119"><a href="#cb22-119" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-120"><a href="#cb22-120" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Test Loss: </span><span class="sc">{</span>test_loss<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb22-121"><a href="#cb22-121" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Test Accuracy: </span><span class="sc">{</span>test_accuracy<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>test_accuracy<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)&quot;</span>)</span>
<span id="cb22-122"><a href="#cb22-122" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-123"><a href="#cb22-123" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> show_details:</span>
<span id="cb22-124"><a href="#cb22-124" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Per-class accuracy:&quot;</span>)</span>
<span id="cb22-125"><a href="#cb22-125" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, acc <span class="kw">in</span> <span class="bu">enumerate</span>(class_accuracies):</span>
<span id="cb22-126"><a href="#cb22-126" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;  Digit </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>acc<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>acc<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)&quot;</span>)</span>
<span id="cb22-127"><a href="#cb22-127" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-128"><a href="#cb22-128" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Worst performing digit: </span><span class="sc">{</span>np<span class="sc">.</span>argmin(class_accuracies)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">min</span>(class_accuracies)<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)&quot;</span>)</span>
<span id="cb22-129"><a href="#cb22-129" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Best performing digit: </span><span class="sc">{</span>np<span class="sc">.</span>argmax(class_accuracies)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">max</span>(class_accuracies)<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)&quot;</span>)</span>
<span id="cb22-130"><a href="#cb22-130" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-131"><a href="#cb22-131" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb22-132"><a href="#cb22-132" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;test_loss&#39;</span>: test_loss,</span>
<span id="cb22-133"><a href="#cb22-133" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;test_accuracy&#39;</span>: test_accuracy,</span>
<span id="cb22-134"><a href="#cb22-134" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;class_accuracies&#39;</span>: class_accuracies,</span>
<span id="cb22-135"><a href="#cb22-135" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;predictions&#39;</span>: predictions</span>
<span id="cb22-136"><a href="#cb22-136" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb22-137"><a href="#cb22-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-138"><a href="#cb22-138" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Evaluation and visualization functions ready!&quot;</span>)</span>
<span id="cb22-139"><a href="#cb22-139" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Functions: plot_training_history, create_confusion_matrix, show_predictions, evaluate_model&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Evaluation and visualization functions ready!
Functions: plot_training_history, create_confusion_matrix, show_predictions, evaluate_model
</code></pre>
</div>
</div>
<div id="877c4126" class="cell code" data-execution_count="18">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the Neural Network Model</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot; Starting Neural Network Training!&quot;</span>)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;=&quot;</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create and initialize the neural network</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Architecture: 784 -&gt; 128 -&gt; 64 -&gt; 10 (optimized for MNIST)</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>neural_net <span class="op">=</span> NeuralNetwork(</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    layer_sizes<span class="op">=</span>[<span class="dv">784</span>, <span class="dv">128</span>, <span class="dv">64</span>, <span class="dv">10</span>],</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">0.001</span>,</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    l2_lambda<span class="op">=</span><span class="fl">0.01</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>training_history <span class="op">=</span> train_network(</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    neural_network<span class="op">=</span>neural_net,</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    X_train<span class="op">=</span>X_train,</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    Y_train<span class="op">=</span>Y_train,</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    X_val<span class="op">=</span>X_val,</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    Y_val<span class="op">=</span>Y_val,</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    use_adam<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">True</span></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st"> Training completed!&quot;</span>)</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot; Plotting training history...&quot;</span>)</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot training progress</span></span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>plot_training_history(training_history)</span></code></pre></div>
<div class="output stream stdout">
<pre><code> Starting Neural Network Training!
============================================================
Neural Network initialized:
Architecture: 784 -&gt; 128 -&gt; 64 -&gt; 10
Total parameters: 109386
Starting training...
Architecture: [784, 128, 64, 10]
Optimizer: Adam
Batch size: 128, Batches per epoch: 375
------------------------------------------------------------
Epoch   5/50 | Train Loss: 0.5447 | Train Acc: 0.9392 | Val Loss: 0.5394 | Val Acc: 0.9392 | Time: 1.55s
Epoch  10/50 | Train Loss: 0.5276 | Train Acc: 0.9442 | Val Loss: 0.5227 | Val Acc: 0.9458 | Time: 1.39s
Epoch  15/50 | Train Loss: 0.5224 | Train Acc: 0.9452 | Val Loss: 0.5134 | Val Acc: 0.9490 | Time: 1.41s
Epoch  20/50 | Train Loss: 0.5185 | Train Acc: 0.9463 | Val Loss: 0.5061 | Val Acc: 0.9527 | Time: 1.53s
Epoch  25/50 | Train Loss: 0.5118 | Train Acc: 0.9477 | Val Loss: 0.5020 | Val Acc: 0.9513 | Time: 1.53s
Epoch  30/50 | Train Loss: 0.5095 | Train Acc: 0.9487 | Val Loss: 0.5037 | Val Acc: 0.9508 | Time: 1.54s
Epoch  35/50 | Train Loss: 0.5091 | Train Acc: 0.9486 | Val Loss: 0.4988 | Val Acc: 0.9533 | Time: 1.56s
Epoch  40/50 | Train Loss: 0.5082 | Train Acc: 0.9483 | Val Loss: 0.4979 | Val Acc: 0.9518 | Time: 1.56s
Epoch  45/50 | Train Loss: 0.5047 | Train Acc: 0.9503 | Val Loss: 0.4984 | Val Acc: 0.9507 | Time: 1.55s
Epoch  50/50 | Train Loss: 0.5038 | Train Acc: 0.9499 | Val Loss: 0.4929 | Val Acc: 0.9538 | Time: 1.61s
------------------------------------------------------------
Training completed!
Best validation loss: 0.4926
Final validation accuracy: 0.9538

 Training completed!
 Plotting training history...
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_637a505316254e4c82a7b332a1076792/8ff8cd7f872f881850b24689a25622023589610a.png" /></p>
</div>
</div>
<div id="794bf955" class="cell code" data-execution_count="19">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Comprehensive Model Evaluation</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot; Evaluating Trained Model&quot;</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;=&quot;</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate on test set</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>test_results <span class="op">=</span> evaluate_model(neural_net, X_test, Y_test, show_details<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st"> Creating Confusion Matrix...&quot;</span>)</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>confusion_matrix <span class="op">=</span> create_confusion_matrix(Y_test, test_results[<span class="st">&#39;predictions&#39;</span>])</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">  Showing Sample Predictions...&quot;</span>)</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>show_predictions(neural_net, X_test, Y_test, num_samples<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st"> Final Model Performance Summary:&quot;</span>)</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot; Test Accuracy: </span><span class="sc">{</span>test_results[<span class="st">&#39;test_accuracy&#39;</span>]<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%&quot;</span>)</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot; Test Loss: </span><span class="sc">{</span>test_results[<span class="st">&#39;test_loss&#39;</span>]<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Find best and worst examples</span></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> test_results[<span class="st">&#39;predictions&#39;</span>]</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>y_pred_labels <span class="op">=</span> np.argmax(predictions, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>y_true_labels <span class="op">=</span> np.argmax(Y_test, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>confidence_scores <span class="op">=</span> np.<span class="bu">max</span>(predictions, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Most confident correct predictions</span></span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>correct_mask <span class="op">=</span> (y_pred_labels <span class="op">==</span> y_true_labels)</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> np.<span class="bu">any</span>(correct_mask):</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>    most_confident_correct <span class="op">=</span> np.argmax(confidence_scores <span class="op">*</span> correct_mask)</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss"> Most confident correct prediction:&quot;</span>)</span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;   Index: </span><span class="sc">{</span>most_confident_correct<span class="sc">}</span><span class="ss">, True: </span><span class="sc">{</span>y_true_labels[most_confident_correct]<span class="sc">}</span><span class="ss">, &quot;</span></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>          <span class="ss">f&quot;Pred: </span><span class="sc">{</span>y_pred_labels[most_confident_correct]<span class="sc">}</span><span class="ss">, Confidence: </span><span class="sc">{</span>confidence_scores[most_confident_correct]<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Most confident incorrect predictions</span></span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a>incorrect_mask <span class="op">=</span> (y_pred_labels <span class="op">!=</span> y_true_labels)</span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> np.<span class="bu">any</span>(incorrect_mask):</span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a>    most_confident_incorrect <span class="op">=</span> np.argmax(confidence_scores <span class="op">*</span> incorrect_mask)</span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot; Most confident incorrect prediction:&quot;</span>)</span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;   Index: </span><span class="sc">{</span>most_confident_incorrect<span class="sc">}</span><span class="ss">, True: </span><span class="sc">{</span>y_true_labels[most_confident_incorrect]<span class="sc">}</span><span class="ss">, &quot;</span></span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a>          <span class="ss">f&quot;Pred: </span><span class="sc">{</span>y_pred_labels[most_confident_incorrect]<span class="sc">}</span><span class="ss">, Confidence: </span><span class="sc">{</span>confidence_scores[most_confident_incorrect]<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss"> Total Parameters: </span><span class="sc">{</span>neural_net<span class="sc">.</span>_count_parameters()<span class="sc">:,}</span><span class="ss">&quot;</span>)</span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot; Average Training Time per Epoch: </span><span class="sc">{</span>np<span class="sc">.</span>mean(training_history[<span class="st">&#39;epoch_time&#39;</span>])<span class="sc">:.2f}</span><span class="ss">s&quot;</span>)</span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;=&quot;</span> <span class="op">*</span> <span class="dv">50</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code> Evaluating Trained Model
==================================================
Evaluating model on test set...
Test Loss: 0.4932
Test Accuracy: 0.9529 (95.29%)

Per-class accuracy:
  Digit 0: 0.9908 (99.08%)
  Digit 1: 0.9841 (98.41%)
  Digit 2: 0.9486 (94.86%)
  Digit 3: 0.9535 (95.35%)
  Digit 4: 0.9562 (95.62%)
  Digit 5: 0.9496 (94.96%)
  Digit 6: 0.9499 (94.99%)
  Digit 7: 0.9465 (94.65%)
  Digit 8: 0.9107 (91.07%)
  Digit 9: 0.9346 (93.46%)

Worst performing digit: 8 (91.07%)
Best performing digit: 0 (99.08%)

 Creating Confusion Matrix...
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_637a505316254e4c82a7b332a1076792/404d82c2f8c5deadecfc44537126f9240ab4214f.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
  Showing Sample Predictions...
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_637a505316254e4c82a7b332a1076792/12acc037ff23faadc8e750290187e63c0cb752ff.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
 Final Model Performance Summary:
 Test Accuracy: 95.29%
 Test Loss: 0.4932

 Most confident correct prediction:
   Index: 8528, True: 0, Pred: 0, Confidence: 0.9999
 Most confident incorrect prediction:
   Index: 4601, True: 8, Pred: 4, Confidence: 0.9731

 Total Parameters: 109,386
 Average Training Time per Epoch: 1.52s
==================================================
</code></pre>
</div>
</div>
<div id="56b59177" class="cell code" data-execution_count="20">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Model Analysis and Interpretation</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot; Neural Network Analysis &amp; Insights&quot;</span>)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;=&quot;</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Analyze weight distributions</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot; Weight Distribution Analysis:&quot;</span>)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, neural_net.num_layers):</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">=</span> neural_net.weights[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>]</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Layer </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> weights - Mean: </span><span class="sc">{</span>weights<span class="sc">.</span>mean()<span class="sc">:.6f}</span><span class="ss">, Std: </span><span class="sc">{</span>weights<span class="sc">.</span>std()<span class="sc">:.6f}</span><span class="ss">, &quot;</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>          <span class="ss">f&quot;Min: </span><span class="sc">{</span>weights<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.6f}</span><span class="ss">, Max: </span><span class="sc">{</span>weights<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.6f}</span><span class="ss">&quot;</span>)</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize first layer weights (input to hidden1)</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st"> Visualizing First Layer Weights (784 -&gt; 128):&quot;</span>)</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>first_layer_weights <span class="op">=</span> neural_net.weights[<span class="st">&#39;W1&#39;</span>]  <span class="co"># Shape: (784, 128)</span></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Select first 25 neurons to visualize</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">5</span>, <span class="dv">5</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">12</span>))</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">25</span>):</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>    row, col <span class="op">=</span> i <span class="op">//</span> <span class="dv">5</span>, i <span class="op">%</span> <span class="dv">5</span></span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Reshape weights back to 28x28 image format</span></span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>    weight_image <span class="op">=</span> first_layer_weights[:, i].reshape(<span class="dv">28</span>, <span class="dv">28</span>)</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>    axes[row, col].imshow(weight_image, cmap<span class="op">=</span><span class="st">&#39;RdBu&#39;</span>, vmin<span class="op">=-</span>weight_image.std()<span class="op">*</span><span class="dv">2</span>, vmax<span class="op">=</span>weight_image.std()<span class="op">*</span><span class="dv">2</span>)</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>    axes[row, col].set_title(<span class="ss">f&#39;Neuron </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">&#39;</span>, fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>    axes[row, col].axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;First Layer Weight Visualizations</span><span class="ch">\n</span><span class="st">(What each neuron &quot;looks for&quot; in input)&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Performance insights</span></span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st"> Model Insights:&quot;</span>)</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>best_val_acc <span class="op">=</span> <span class="bu">max</span>(training_history[<span class="st">&#39;val_acc&#39;</span>])</span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>final_val_acc <span class="op">=</span> training_history[<span class="st">&#39;val_acc&#39;</span>][<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot; Best Validation Accuracy: </span><span class="sc">{</span>best_val_acc<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>best_val_acc<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)&quot;</span>)</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot; Final Validation Accuracy: </span><span class="sc">{</span>final_val_acc<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>final_val_acc<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)&quot;</span>)</span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Overfitting analysis</span></span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>train_val_gap <span class="op">=</span> <span class="bu">abs</span>(training_history[<span class="st">&#39;train_acc&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span> training_history[<span class="st">&#39;val_acc&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot; Train-Validation Gap: </span><span class="sc">{</span>train_val_gap<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span><span class="st">&#39;Overfitting detected&#39;</span> <span class="cf">if</span> train_val_gap <span class="op">&gt;</span> <span class="fl">0.05</span> <span class="cf">else</span> <span class="st">&#39;Good generalization&#39;</span><span class="sc">}</span><span class="ss">)&quot;</span>)</span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Architecture efficiency</span></span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a>params_per_accuracy <span class="op">=</span> neural_net._count_parameters() <span class="op">/</span> (test_results[<span class="st">&#39;test_accuracy&#39;</span>] <span class="op">*</span> <span class="dv">100</span>)</span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;  Parameters per accuracy point: </span><span class="sc">{</span>params_per_accuracy<span class="sc">:.0f}</span><span class="ss">&quot;</span>)</span>
<span id="cb30-46"><a href="#cb30-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-47"><a href="#cb30-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st"> MNIST Neural Network - From Scratch Implementation Summary:&quot;</span>)</span>
<span id="cb30-48"><a href="#cb30-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;=&quot;</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb30-49"><a href="#cb30-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot; Successfully implemented:&quot;</span>)</span>
<span id="cb30-50"><a href="#cb30-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;    Complete neural network from scratch using only NumPy&quot;</span>)</span>
<span id="cb30-51"><a href="#cb30-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;    ReLU activation for hidden layers&quot;</span>)</span>
<span id="cb30-52"><a href="#cb30-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;    Softmax activation for output layer&quot;</span>)</span>
<span id="cb30-53"><a href="#cb30-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;    Cross-entropy loss with L2 regularization&quot;</span>)</span>
<span id="cb30-54"><a href="#cb30-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;    Adam optimizer with adaptive learning rates&quot;</span>)</span>
<span id="cb30-55"><a href="#cb30-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;    He/Xavier weight initialization&quot;</span>)</span>
<span id="cb30-56"><a href="#cb30-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;    Mini-batch training with early stopping&quot;</span>)</span>
<span id="cb30-57"><a href="#cb30-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;    Comprehensive evaluation and visualization&quot;</span>)</span>
<span id="cb30-58"><a href="#cb30-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-59"><a href="#cb30-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">  Final Results:&quot;</span>)</span>
<span id="cb30-60"><a href="#cb30-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;    Architecture: </span><span class="sc">{</span><span class="st">&#39;  &#39;</span><span class="sc">.</span>join(<span class="bu">map</span>(<span class="bu">str</span>, neural_net.layer_sizes))<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb30-61"><a href="#cb30-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;    Total Parameters: </span><span class="sc">{</span>neural_net<span class="sc">.</span>_count_parameters()<span class="sc">:,}</span><span class="ss">&quot;</span>)</span>
<span id="cb30-62"><a href="#cb30-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;    Test Accuracy: </span><span class="sc">{</span>test_results[<span class="st">&#39;test_accuracy&#39;</span>]<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%&quot;</span>)</span>
<span id="cb30-63"><a href="#cb30-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;    Training Time: ~</span><span class="sc">{</span><span class="bu">sum</span>(training_history[<span class="st">&#39;epoch_time&#39;</span>])<span class="sc">:.1f}</span><span class="ss"> seconds&quot;</span>)</span>
<span id="cb30-64"><a href="#cb30-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-65"><a href="#cb30-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss"> This implementation demonstrates fundamental deep learning concepts&quot;</span>)</span>
<span id="cb30-66"><a href="#cb30-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;   and achieves strong performance on MNIST digit classification!&quot;</span>)</span>
<span id="cb30-67"><a href="#cb30-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;=&quot;</span> <span class="op">*</span> <span class="dv">60</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code> Neural Network Analysis &amp; Insights
============================================================
 Weight Distribution Analysis:
Layer 1 weights - Mean: 0.000100, Std: 0.014440, Min: -0.203784, Max: 0.188006
Layer 2 weights - Mean: 0.002153, Std: 0.048694, Min: -0.269765, Max: 0.294062
Layer 3 weights - Mean: -0.000076, Std: 0.174764, Min: -0.400625, Max: 0.489283

 Visualizing First Layer Weights (784 -&gt; 128):
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_637a505316254e4c82a7b332a1076792/54246e01819155411a771b0269fc581a67cb3aba.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
 Model Insights:
 Best Validation Accuracy: 0.9558 (95.58%)
 Final Validation Accuracy: 0.9538 (95.38%)
 Train-Validation Gap: 0.0040 (Good generalization)
  Parameters per accuracy point: 1148

 MNIST Neural Network - From Scratch Implementation Summary:
============================================================
 Successfully implemented:
    Complete neural network from scratch using only NumPy
    ReLU activation for hidden layers
    Softmax activation for output layer
    Cross-entropy loss with L2 regularization
    Adam optimizer with adaptive learning rates
    He/Xavier weight initialization
    Mini-batch training with early stopping
    Comprehensive evaluation and visualization

  Final Results:
    Architecture: 784  128  64  10
    Total Parameters: 109,386
    Test Accuracy: 95.29%
    Training Time: ~76.2 seconds

 This implementation demonstrates fundamental deep learning concepts
   and achieves strong performance on MNIST digit classification!
============================================================
</code></pre>
</div>
</div>
<div id="fbfbd07a" class="cell code" data-execution_count="21">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pickle</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Save and Load Neural Network Model</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> save_neural_network(neural_network, filepath<span class="op">=</span><span class="st">&quot;mnist_neural_network.json&quot;</span>, include_metadata<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Save the trained neural network to a file for later use</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>        model_data <span class="op">=</span> {</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;layer_sizes&#39;</span>: neural_network.layer_sizes,</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;weights&#39;</span>: {},</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;biases&#39;</span>: {},</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;learning_rate&#39;</span>: neural_network.learning_rate,</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;l2_lambda&#39;</span>: neural_network.l2_lambda,</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;num_layers&#39;</span>: neural_network.num_layers</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert weights and biases to regular Python lists for JSON serialization</span></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, neural_network.num_layers):</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>            model_data[<span class="st">&#39;weights&#39;</span>][<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> neural_network.weights[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>].tolist()</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>            model_data[<span class="st">&#39;biases&#39;</span>][<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> neural_network.biases[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>].tolist()</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add metadata if requested</span></span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> include_metadata:</span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>            metadata <span class="op">=</span> {</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;total_parameters&#39;</span>: neural_network._count_parameters(),</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;architecture_description&#39;</span>: <span class="ss">f&quot;</span><span class="sc">{</span><span class="st">&#39; -&gt; &#39;</span><span class="sc">.</span>join(<span class="bu">map</span>(<span class="bu">str</span>, neural_network.layer_sizes))<span class="sc">}</span><span class="ss">&quot;</span></span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Safely add training results if available</span></span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="st">&#39;test_results&#39;</span> <span class="kw">in</span> <span class="bu">globals</span>() <span class="kw">and</span> test_results:</span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a>                metadata[<span class="st">&#39;test_accuracy&#39;</span>] <span class="op">=</span> test_results.get(<span class="st">&#39;test_accuracy&#39;</span>, <span class="fl">0.0</span>)</span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="st">&#39;training_history&#39;</span> <span class="kw">in</span> <span class="bu">globals</span>() <span class="kw">and</span> training_history:</span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a>                metadata[<span class="st">&#39;training_epochs&#39;</span>] <span class="op">=</span> <span class="bu">len</span>(training_history.get(<span class="st">&#39;train_acc&#39;</span>, []))</span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a>                val_acc <span class="op">=</span> training_history.get(<span class="st">&#39;val_acc&#39;</span>, [])</span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> val_acc:</span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a>                    metadata[<span class="st">&#39;final_val_accuracy&#39;</span>] <span class="op">=</span> val_acc[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-45"><a href="#cb33-45" aria-hidden="true" tabindex="-1"></a>            model_data[<span class="st">&#39;metadata&#39;</span>] <span class="op">=</span> metadata</span>
<span id="cb33-46"><a href="#cb33-46" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-47"><a href="#cb33-47" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Save as JSON</span></span>
<span id="cb33-48"><a href="#cb33-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(filepath, <span class="st">&#39;w&#39;</span>) <span class="im">as</span> f:</span>
<span id="cb33-49"><a href="#cb33-49" aria-hidden="true" tabindex="-1"></a>            json.dump(model_data, f, indent<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb33-50"><a href="#cb33-50" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-51"><a href="#cb33-51" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot; Neural network saved to: </span><span class="sc">{</span>filepath<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb33-52"><a href="#cb33-52" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot; Architecture: </span><span class="sc">{</span>model_data[<span class="st">&#39;metadata&#39;</span>][<span class="st">&#39;architecture_description&#39;</span>] <span class="cf">if</span> <span class="st">&#39;metadata&#39;</span> <span class="kw">in</span> model_data <span class="cf">else</span> <span class="st">&#39;N/A&#39;</span><span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb33-53"><a href="#cb33-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">&#39;metadata&#39;</span> <span class="kw">in</span> model_data <span class="kw">and</span> <span class="st">&#39;test_accuracy&#39;</span> <span class="kw">in</span> model_data[<span class="st">&#39;metadata&#39;</span>]:</span>
<span id="cb33-54"><a href="#cb33-54" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot; Test accuracy: </span><span class="sc">{</span>model_data[<span class="st">&#39;metadata&#39;</span>][<span class="st">&#39;test_accuracy&#39;</span>]<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb33-55"><a href="#cb33-55" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-56"><a href="#cb33-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> model_data</span>
<span id="cb33-57"><a href="#cb33-57" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-58"><a href="#cb33-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb33-59"><a href="#cb33-59" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot; Error saving model: </span><span class="sc">{</span><span class="bu">str</span>(e)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb33-60"><a href="#cb33-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb33-61"><a href="#cb33-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-62"><a href="#cb33-62" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_neural_network(filepath):</span>
<span id="cb33-63"><a href="#cb33-63" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb33-64"><a href="#cb33-64" aria-hidden="true" tabindex="-1"></a><span class="co">    Load a saved neural network from file</span></span>
<span id="cb33-65"><a href="#cb33-65" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb33-66"><a href="#cb33-66" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb33-67"><a href="#cb33-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(filepath, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> f:</span>
<span id="cb33-68"><a href="#cb33-68" aria-hidden="true" tabindex="-1"></a>            model_data <span class="op">=</span> json.load(f)</span>
<span id="cb33-69"><a href="#cb33-69" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-70"><a href="#cb33-70" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create new neural network instance</span></span>
<span id="cb33-71"><a href="#cb33-71" aria-hidden="true" tabindex="-1"></a>        loaded_nn <span class="op">=</span> NeuralNetwork(</span>
<span id="cb33-72"><a href="#cb33-72" aria-hidden="true" tabindex="-1"></a>            layer_sizes<span class="op">=</span>model_data[<span class="st">&#39;layer_sizes&#39;</span>],</span>
<span id="cb33-73"><a href="#cb33-73" aria-hidden="true" tabindex="-1"></a>            learning_rate<span class="op">=</span>model_data[<span class="st">&#39;learning_rate&#39;</span>],</span>
<span id="cb33-74"><a href="#cb33-74" aria-hidden="true" tabindex="-1"></a>            l2_lambda<span class="op">=</span>model_data[<span class="st">&#39;l2_lambda&#39;</span>]</span>
<span id="cb33-75"><a href="#cb33-75" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb33-76"><a href="#cb33-76" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-77"><a href="#cb33-77" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Load weights and biases</span></span>
<span id="cb33-78"><a href="#cb33-78" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, loaded_nn.num_layers):</span>
<span id="cb33-79"><a href="#cb33-79" aria-hidden="true" tabindex="-1"></a>            loaded_nn.weights[<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> np.array(model_data[<span class="st">&#39;weights&#39;</span>][<span class="ss">f&#39;W</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>])</span>
<span id="cb33-80"><a href="#cb33-80" aria-hidden="true" tabindex="-1"></a>            loaded_nn.biases[<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>] <span class="op">=</span> np.array(model_data[<span class="st">&#39;biases&#39;</span>][<span class="ss">f&#39;b</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&#39;</span>])</span>
<span id="cb33-81"><a href="#cb33-81" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-82"><a href="#cb33-82" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot; Neural network loaded from: </span><span class="sc">{</span>filepath<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb33-83"><a href="#cb33-83" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">&#39;metadata&#39;</span> <span class="kw">in</span> model_data:</span>
<span id="cb33-84"><a href="#cb33-84" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot; Architecture: </span><span class="sc">{</span>model_data[<span class="st">&#39;metadata&#39;</span>]<span class="sc">.</span>get(<span class="st">&#39;architecture_description&#39;</span>, <span class="st">&#39;N/A&#39;</span>)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb33-85"><a href="#cb33-85" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="st">&#39;test_accuracy&#39;</span> <span class="kw">in</span> model_data[<span class="st">&#39;metadata&#39;</span>]:</span>
<span id="cb33-86"><a href="#cb33-86" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f&quot; Original test accuracy: </span><span class="sc">{</span>model_data[<span class="st">&#39;metadata&#39;</span>][<span class="st">&#39;test_accuracy&#39;</span>]<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb33-87"><a href="#cb33-87" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-88"><a href="#cb33-88" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> loaded_nn</span>
<span id="cb33-89"><a href="#cb33-89" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-90"><a href="#cb33-90" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">FileNotFoundError</span>:</span>
<span id="cb33-91"><a href="#cb33-91" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot; File not found: </span><span class="sc">{</span>filepath<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb33-92"><a href="#cb33-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb33-93"><a href="#cb33-93" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb33-94"><a href="#cb33-94" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot; Error loading model: </span><span class="sc">{</span><span class="bu">str</span>(e)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb33-95"><a href="#cb33-95" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb33-96"><a href="#cb33-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-97"><a href="#cb33-97" aria-hidden="true" tabindex="-1"></a><span class="co"># Main execution</span></span>
<span id="cb33-98"><a href="#cb33-98" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot; Neural Network Save/Load Functions Ready!&quot;</span>)</span>
<span id="cb33-99"><a href="#cb33-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-100"><a href="#cb33-100" aria-hidden="true" tabindex="-1"></a><span class="co"># Only proceed if neural_net exists (from training)</span></span>
<span id="cb33-101"><a href="#cb33-101" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">&#39;neural_net&#39;</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb33-102"><a href="#cb33-102" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st"> Saving trained neural network...&quot;</span>)</span>
<span id="cb33-103"><a href="#cb33-103" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-104"><a href="#cb33-104" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Save the model</span></span>
<span id="cb33-105"><a href="#cb33-105" aria-hidden="true" tabindex="-1"></a>    model_filename <span class="op">=</span> <span class="st">&quot;mnist_neural_network.json&quot;</span> </span>
<span id="cb33-106"><a href="#cb33-106" aria-hidden="true" tabindex="-1"></a>    saved_model_data <span class="op">=</span> save_neural_network(neural_net, model_filename, include_metadata<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb33-107"><a href="#cb33-107" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-108"><a href="#cb33-108" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> saved_model_data:</span>
<span id="cb33-109"><a href="#cb33-109" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Test loading</span></span>
<span id="cb33-110"><a href="#cb33-110" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st"> Testing model loading...&quot;</span>)</span>
<span id="cb33-111"><a href="#cb33-111" aria-hidden="true" tabindex="-1"></a>        loaded_model <span class="op">=</span> load_neural_network(model_filename)</span>
<span id="cb33-112"><a href="#cb33-112" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-113"><a href="#cb33-113" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> loaded_model <span class="kw">and</span> <span class="st">&#39;X_test&#39;</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb33-114"><a href="#cb33-114" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Verify loaded model works</span></span>
<span id="cb33-115"><a href="#cb33-115" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st"> Verifying loaded model...&quot;</span>)</span>
<span id="cb33-116"><a href="#cb33-116" aria-hidden="true" tabindex="-1"></a>            test_sample <span class="op">=</span> X_test[:<span class="dv">3</span>]  <span class="co"># Small sample for testing</span></span>
<span id="cb33-117"><a href="#cb33-117" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-118"><a href="#cb33-118" aria-hidden="true" tabindex="-1"></a>            original_pred <span class="op">=</span> neural_net.predict(test_sample)</span>
<span id="cb33-119"><a href="#cb33-119" aria-hidden="true" tabindex="-1"></a>            loaded_pred <span class="op">=</span> loaded_model.predict(test_sample)</span>
<span id="cb33-120"><a href="#cb33-120" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-121"><a href="#cb33-121" aria-hidden="true" tabindex="-1"></a>            predictions_match <span class="op">=</span> np.allclose(original_pred, loaded_pred, rtol<span class="op">=</span><span class="fl">1e-10</span>)</span>
<span id="cb33-122"><a href="#cb33-122" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot; Predictions match: </span><span class="sc">{</span>predictions_match<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb33-123"><a href="#cb33-123" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-124"><a href="#cb33-124" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> predictions_match:</span>
<span id="cb33-125"><a href="#cb33-125" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">&quot; Model successfully saved and loaded!&quot;</span>)</span>
<span id="cb33-126"><a href="#cb33-126" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f&quot; File size: </span><span class="sc">{</span>os<span class="sc">.</span>path<span class="sc">.</span>getsize(model_filename) <span class="op">/</span> <span class="dv">1024</span><span class="sc">:.1f}</span><span class="ss"> KB&quot;</span>)</span>
<span id="cb33-127"><a href="#cb33-127" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb33-128"><a href="#cb33-128" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">&quot; Warning: Predictions don&#39;t match exactly&quot;</span>)</span>
<span id="cb33-129"><a href="#cb33-129" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-130"><a href="#cb33-130" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss"> Frontend Integration Ready:&quot;</span>)</span>
<span id="cb33-131"><a href="#cb33-131" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;    File: </span><span class="sc">{</span>model_filename<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb33-132"><a href="#cb33-132" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;    Format: JSON&quot;</span>)</span>
<span id="cb33-133"><a href="#cb33-133" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;    Input: 784 features (normalized 0-1)&quot;</span>)</span>
<span id="cb33-134"><a href="#cb33-134" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;    Output: 10 class probabilities&quot;</span>)</span>
<span id="cb33-135"><a href="#cb33-135" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-136"><a href="#cb33-136" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb33-137"><a href="#cb33-137" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;  Neural network not found! Please run training cells first.&quot;</span>)</span>
<span id="cb33-138"><a href="#cb33-138" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;   Creating demo network for testing save/load functions...&quot;</span>)</span>
<span id="cb33-139"><a href="#cb33-139" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-140"><a href="#cb33-140" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Demo network</span></span>
<span id="cb33-141"><a href="#cb33-141" aria-hidden="true" tabindex="-1"></a>    demo_net <span class="op">=</span> NeuralNetwork([<span class="dv">784</span>, <span class="dv">128</span>, <span class="dv">64</span>, <span class="dv">10</span>])</span>
<span id="cb33-142"><a href="#cb33-142" aria-hidden="true" tabindex="-1"></a>    save_neural_network(demo_net, <span class="st">&quot;demo_model.json&quot;</span>, include_metadata<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb33-143"><a href="#cb33-143" aria-hidden="true" tabindex="-1"></a>    loaded_demo <span class="op">=</span> load_neural_network(<span class="st">&quot;demo_model.json&quot;</span>)</span>
<span id="cb33-144"><a href="#cb33-144" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-145"><a href="#cb33-145" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> loaded_demo:</span>
<span id="cb33-146"><a href="#cb33-146" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot; Save/load functions working correctly!&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code> Neural Network Save/Load Functions Ready!

 Saving trained neural network...
 Neural network saved to: mnist_neural_network.json
 Architecture: 784 -&gt; 128 -&gt; 64 -&gt; 10
 Test accuracy: 0.9529

 Testing model loading...
Neural Network initialized:
Architecture: 784 -&gt; 128 -&gt; 64 -&gt; 10
Total parameters: 109386
 Neural network loaded from: mnist_neural_network.json
 Architecture: 784 -&gt; 128 -&gt; 64 -&gt; 10
 Original test accuracy: 0.9529

 Verifying loaded model...
 Predictions match: True
 Model successfully saved and loaded!
 File size: 3493.9 KB

 Frontend Integration Ready:
    File: mnist_neural_network.json
    Format: JSON
    Input: 784 features (normalized 0-1)
    Output: 10 class probabilities
</code></pre>
</div>
</div>
</body>
</html>
